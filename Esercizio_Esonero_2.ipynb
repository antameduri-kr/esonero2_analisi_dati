{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1v2UmMk5Dmx",
        "outputId": "493d2dde-b336-49b8-8721-194e20748b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset iniziali creati\n",
            "   product_id     category   brand   price\n",
            "0           1      Fashion  BrandC  107.28\n",
            "1           2  Electronics  BrandC  108.03\n",
            "2           3      Fashion  BrandA  166.04\n",
            "3           4      Fashion  BrandC  271.88\n",
            "4           5  Electronics  BrandB  227.33\n",
            "        date  product_id  quantity  customer_id\n",
            "0 2023-01-01           3         3          163\n",
            "1 2023-01-01           9         3          150\n",
            "2 2023-01-01           7         1          172\n",
            "3 2023-01-01           7         2          103\n",
            "4 2023-01-01           9         2          108\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Impostiamo il \"seed\" del generatore casuale. Ogni volte che lo script verrà eseguito i numeri casuali generati saranno gli stessi\n",
        "np.random.seed(42)\n",
        "\n",
        "# --- DATI ---\n",
        "# Verrà creato un dizionario dove le chiavi saranno i nomi delle colonne, e ogni valore sarà la lista/serie di dati di quella colonna\n",
        "\n",
        "data_prodotto = {\n",
        "    'product_id': range (1,11), # valori da 1 a 10\n",
        "    'category': np.random.choice([\"Electronics\", \"Home\", \"Fashion\"], 10), # sceglie a caso una categoria tra quelle indicate, generando 10 valori\n",
        "    'brand': np.random.choice([\"BrandA\", \"BrandB\", \"BrandC\"], 10), # sceglie a caso uno dei 3 brand, generando sempre 10 valori\n",
        "    'price': np.random.uniform(20,500,10).round(2) # genera 10 numeri casuali in virgola mobile tra 20 e 500 e poi arrotonda i numeri a 2 decimali\n",
        "}\n",
        "\n",
        "\n",
        "# Generiamo DATE e VENDITE relative all'anno 2023\n",
        "dates = pd.date_range(start='2023-01-01', end = '2023-12-31', freq='D') # creaiamo un array con una sequenza di date giornaliere, \"D\" = daily, dal 1 gennaio al 31 dicembre 2023 inclusi\n",
        "data_vendite = [] # creata una lista vuota, nella quale verranno aggiunte tutte le \"righe\" delle vendite, una per ogni vendita\n",
        "for date in dates: # per ogni giorno contenuto in dates, esegue il blocco dentro il for\n",
        "  # Generiamo Tra 0 e 5 vendite al giorno\n",
        "  n_sales = np.random.randint(0,6) #decide quante vendite ci saranno per ogni giorno, tra 0 e 5, quindi possono esserci anche 0 vendite\n",
        "  for _ in range(n_sales):  # esegue un ciclo n_sales volte\n",
        "    data_vendite.append({  # aggiunge alla lista data_vendite un dizionario che rapprenseta un singola riga di vendita\n",
        "        'date': date,\n",
        "        'product_id': np.random.randint(1,11), # sceglie un prodotto casuale tra 1 e 10\n",
        "        'quantity': np.random.randint(1,4), # sceglie la quantità venduta tra 1 e 3\n",
        "        'customer_id': np.random.randint(100,200) # assegna un id cliente casuale tra 100 e 199\n",
        "    })\n",
        "\n",
        "df_products = pd.DataFrame(data_prodotto) # creaiamo un DataFrame a partire dal dizionario data_prodotto, come risultato avremo una tabella con 10 righe e 4 colonne\n",
        "df_sales = pd.DataFrame(data_vendite) # converte la lista di dizioonari data_vendite in un DataFrame. Ogni dizionario è una riga di vendite. il n di righe dipende da quante vendite casuali sono generate\n",
        "\n",
        "print(\"Dataset iniziali creati\")\n",
        "print(df_products.head())\n",
        "print(df_sales.head())\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 1: Inquinamento dei Dati (Generazione di Null e Duplicati)**\n",
        "I dati reali non sono mai perfetti. Dobbiamo, quindi, simulare in dataset \"sporco\".\n",
        "\n",
        "\n",
        "1.   **Generazione di valori Nulli:**\n",
        "\n",
        "\n",
        "*   Utilizzando `numpy` e l'indicizzazione di pandas, assegna `np.nan` (valori nulli) al 5% della colonna `quantity` in `df_sales`\n",
        "*   Assegna `np.nan` alla colonna `brand` di `df_products` per i prodotti con `product_id` pari\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "2.   **Generazione di Duplicati**:\n",
        "\n",
        "\n",
        "*   Crea una copia delle prime 10 righe di df_sales e concatenale al dataframe originale. Ora hai dei duplicati intenzionali\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LkqIRpoZGQGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generazione di valori nulli"
      ],
      "metadata": {
        "id": "89K-15dASN3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcoliamo il 5% delle righe, arrotondato per eccesso a minimo 1\n",
        "n_nan = max(1,int(len(df_sales)*0.05))\n",
        "\n",
        "# Scegliamo gli indici casuali di n_nan righe\n",
        "idx_nan = np.random.choice(df_sales.index, size=n_nan, replace=False)\n",
        "\n",
        "# Assegniamo i valori NaN alla colonna quantity delle righe con indice idx_nan\n",
        "df_sales.loc[idx_nan, 'quantity'] = np.nan\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZgC1i-vuR49e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# L'idea è quella di creare una maschera booleana con % 2 == 0 (così troviamo i product_id pari)\n",
        "# e usiamo .loc per inserire i valori NaN alla colonna brand di df_products\n",
        "\n",
        "mask_pari = (df_products['product_id'] % 2 == 0)\n",
        "df_products.loc[mask_pari, 'brand'] = np.nan\n",
        "\n"
      ],
      "metadata": {
        "id": "1ml2ANmiR4__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generazione dei duplicati"
      ],
      "metadata": {
        "id": "1B5Lq7yUUgkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Facciamo la copia delle prime 10 righe\n",
        "df_sales_copy10 = df_sales.head(10).copy()\n",
        "\n",
        "# Adesso le concateniamo al DataFrame originale tramite il metodo concat\n",
        "df_sales = pd.concat([df_sales, df_sales_copy10], ignore_index=True) # ignore_index non replica gli indici"
      ],
      "metadata": {
        "id": "a5ucmeMKUpPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARTE 2: PULIZIA E CONTROLLO DEI DATI\n",
        "Ora che abbiamo i dati sporchi, bisogna procedere con la \"pulizia dei dati\"\n",
        "\n",
        "\n",
        "\n",
        "*   Visualizza il conteggio dei valori nulli per ogni colonna di entrambi i DataFrame\n",
        "*   Gestisci i null in `df_sales['quantity'] `: sostiuiscili con la media della quantità (arrotondata all'intero più vicino)\n",
        "\n",
        "\n",
        "*   Gestisci i null in `df_products['brand']`: sostiuiscili con la stringa \"Unknown\"\n",
        "*   Identifica e rimuovi le righe duplicate in df_sales mantenendo solo la prima occorenza.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TfeaH-upd8lQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conteggio dei valori nulli per colonna nel DataFrame df_sales\n",
        "nulli_sales = df_sales.isnull().sum()\n",
        "print(\"Valori nulli nel DataFrame df_sales:\")\n",
        "print(nulli_sales)\n",
        "\n",
        "# Conteggio dei valori nulli per colonna nel DataFrame df_products\n",
        "nulli_products = df_products.isnull().sum()\n",
        "print(\"Valori nulli nel DataFrame df_products:\")\n",
        "print(nulli_products)\n"
      ],
      "metadata": {
        "id": "TNDdSNRxfmpq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fec5db3-c0ad-4fef-9499-ed5ee0b9deeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valori nulli nel DataFrame df_sales:\n",
            "date            0\n",
            "product_id      0\n",
            "quantity       44\n",
            "customer_id     0\n",
            "dtype: int64\n",
            "Valori nulli nel DataFrame df_products:\n",
            "product_id    0\n",
            "category      0\n",
            "brand         5\n",
            "price         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 - Calcoliamo la media della colonna ignorando i NaN (pandas lo fa di default) e arrotondandola all'intero più vicino\n",
        "media_quantity = int(round(df_sales['quantity'].mean()))\n",
        "\n",
        "# 2 - Sostituiamo i NaN con il valore della media calcolato, il metodo fillna(x), sostituisce tutti i NaN con il valore x per la colonna indicata\n",
        "df_sales['quantity'] = df_sales['quantity'].fillna(media_quantity)\n",
        "\n",
        "# Aggiungiamo una verifica\n",
        "print(\"NaN rimasti in quantity:\", df_sales['quantity'].isna().sum())\n",
        "print(\"Valore usato per imputazione:\", media_quantity)\n"
      ],
      "metadata": {
        "id": "T7m209DrhhMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28953ab8-815e-4d6d-f53b-18808ad37755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN rimasti in quantity: 0\n",
            "Valore usato per imputazione: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sostituiamo i valori NaN presenti nella colonna brand di df_products con la stringa \"Unknown\"\n",
        "df_products['brand'] = df_products['brand'].fillna(\"Unknown\")\n",
        "\n",
        "# Aggiungiamo una verifica\n",
        "print(\"NaN rimasti in df_products['brand']:\", df_products['brand'].isna().sum())"
      ],
      "metadata": {
        "id": "G_sH2eyukd1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33caefea-a0dc-4aba-da37-e48620163226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN rimasti in df_products['brand']: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifichiamo ed eliminiamo le righe duplicate  in df_sales e manteniamo la prima occorenza\n",
        "\n",
        "# Calcoliamo intanto quante righe duplicate ci sono prima della rimozione\n",
        "print(\"Duplicati prima:\", df_sales.duplicated().sum())\n",
        "\n",
        "# Rimuoviamo i duplicati mantenendo la prima occorenza\n",
        "# Per farlo usiamo il metodo drop_duplicates(keep='first') che elimina tutte le copie successive e lascia la prima\n",
        "# Con reset_index(drop=True), invece, ricreiamo un indice pulito del nuovo DataFrame che va da 0...a N-1\n",
        "df_sales = df_sales.drop_duplicates(keep='first').reset_index(drop=True)\n",
        "\n",
        "# Verifichiamo\n",
        "print(\"Duplicati dopo:\", df_sales.duplicated().sum())\n",
        "print(\"Righe totali dopo:\", len(df_sales))"
      ],
      "metadata": {
        "id": "aVtfjT9GlqaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d9e141-08bd-4bdd-fb8f-b167e39183d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicati prima: 10\n",
            "Duplicati dopo: 0\n",
            "Righe totali dopo: 873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARTE 3: INTEGRAZIONE E GESTIONE DELLE DATE\n",
        "\n",
        "\n",
        "\n",
        "1.   **Analisi Temporale**\n",
        "\n",
        "\n",
        "*   Assicurati che la colonna `date` in `df_sales` sia in formato datetime\n",
        "*   Crea due nuove colonne in `df_sales`: `year` e `month`. Estrai l'anno e il mese della data\n",
        "\n",
        "\n",
        "*   Calcola una colonna `total_price` che sia il risultato di `quantity*price` (attenzione: il prezzo è in `df_products`, non in `df_sales`)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "2.   **Merge (Unione)**\n",
        "\n",
        "\n",
        "*   Esegui un `merge` (left join) tra `df_sales` e `df_products` sulla base di `product_id` per portare le informazioni sui prodotti (categoria,prezzo,marca) dentro il dataframe delle vendite\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8M6bDtDirRYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assicura che df_sales['date'] sia in formato datetime\n",
        "df_sales['date'] = pd.to_datetime(df_sales['date'], errors=\"coerce\")\n",
        "\n",
        "# pd.to_datetime() converte la colonna in datetime\n",
        "# errors=coerce trasforma eventuali valori non convertibili in NaT (null datetime), invece di lanciare un errore\n",
        "\n",
        "# Facciamo una verifica\n",
        "print(df_sales['date'].dtype)\n",
        "print(\"NaT in date:\", df_sales['date'].isna().sum())"
      ],
      "metadata": {
        "id": "c4IJkp1Is6C4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d05cd6b-c384-45fd-e424-a3150d960378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datetime64[ns]\n",
            "NaT in date: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creo le colonne year e month estraendole dalla data\n",
        "df_sales['year'] = df_sales['date'].dt.year\n",
        "df_sales['month'] = df_sales['date'].dt.month\n",
        "\n",
        "# In questo modo ottengo il mese con il nome invece che con il numero\n",
        "# df_sales['month_name'] = df_sales['date'].dt.strftime('%B')"
      ],
      "metadata": {
        "id": "aIzSUcsj9Sln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcolo di una colonna che sia il risultato di qauntity*price\n",
        "df_sales = df_sales.merge(df_products[['product_id', 'price']], on = 'product_id', how = 'left')\n",
        "df_sales['total_price'] = df_sales['quantity'] * df_sales['price']\n",
        "\n",
        "print(df_sales.columns.tolist()) # Controlliamo numero e nome delle colonne di df_sales\n",
        "\n",
        "df_sales = df_sales.merge(\n",
        "    df_products[['product_id', 'category', 'brand']],\n",
        "    on='product_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(df_sales.columns.to_list()) # controlliamo di nuovo dopo il merge\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-9Q_g8IG1nG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd078be-a299-4e24-e699-ee786e980d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['date', 'product_id', 'quantity', 'customer_id', 'year', 'month', 'price', 'total_price']\n",
            "['date', 'product_id', 'quantity', 'customer_id', 'year', 'month', 'price', 'total_price', 'category', 'brand']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 4: Analisi esplorativa (Groupby, Pivot, Filter)\n",
        "Utilizzando il dataframe ottenuto nel punto precedente:\n",
        "\n",
        "\n",
        "*   Filtra le vendite solo per la categoria Electronics\n",
        "*   Di queste vendite mostra le top 3 transazioni per `total_price` più alto\n",
        "\n"
      ],
      "metadata": {
        "id": "34OUgZAjHLsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtro le vendite solo per la categoria Electronics\n",
        "df_sales_electronics = df_sales.loc[df_sales['category'] == 'Electronics'].copy()\n",
        "print(df_sales_electronics)\n",
        "print(\"Numero vendite Electronics:\", len(df_sales_electronics))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLP4GT0oSi18",
        "outputId": "210b420c-43b5-4d04-95ab-00419594dc1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          date  product_id  quantity  customer_id  year  month   price  \\\n",
            "5   2023-01-02           5       2.0          183  2023      1  227.33   \n",
            "9   2023-01-04           6       2.0          103  2023      1  159.79   \n",
            "10  2023-01-05           2       2.0          143  2023      1  108.03   \n",
            "11  2023-01-05           2       2.0          161  2023      1  108.03   \n",
            "15  2023-01-06           2       3.0          152  2023      1  108.03   \n",
            "..         ...         ...       ...          ...   ...    ...     ...   \n",
            "853 2023-12-26           2       2.0          197  2023     12  108.03   \n",
            "855 2023-12-26           6       3.0          139  2023     12  159.79   \n",
            "861 2023-12-28           6       2.0          126  2023     12  159.79   \n",
            "864 2023-12-28           2       1.0          102  2023     12  108.03   \n",
            "866 2023-12-29           6       3.0          151  2023     12  159.79   \n",
            "\n",
            "     total_price     category    brand  \n",
            "5         454.66  Electronics   BrandB  \n",
            "9         319.58  Electronics  Unknown  \n",
            "10        216.06  Electronics  Unknown  \n",
            "11        216.06  Electronics  Unknown  \n",
            "15        324.09  Electronics  Unknown  \n",
            "..           ...          ...      ...  \n",
            "853       216.06  Electronics  Unknown  \n",
            "855       479.37  Electronics  Unknown  \n",
            "861       319.58  Electronics  Unknown  \n",
            "864       108.03  Electronics  Unknown  \n",
            "866       479.37  Electronics  Unknown  \n",
            "\n",
            "[255 rows x 10 columns]\n",
            "Numero vendite Electronics: 255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostro le prime 3 vendite per total_price più alto, ordinando la colonna in modo decrescente e prendendo i primi 3 risultati\n",
        "top3 = df_sales_electronics.sort_values('total_price', ascending=False).head(3)\n",
        "\n",
        "# Mostra le colonne più utili\n",
        "print(top3[['date', 'product_id', 'category', 'brand', 'quantity', 'price', 'total_price']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoVCp8NzT0jj",
        "outputId": "2845a8ec-3d7a-4607-c61f-5e8b0ae1a40f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          date  product_id     category   brand  quantity   price  total_price\n",
            "29  2023-01-12           5  Electronics  BrandB       3.0  227.33       681.99\n",
            "116 2023-02-19           5  Electronics  BrandB       3.0  227.33       681.99\n",
            "211 2023-03-30           5  Electronics  BrandB       3.0  227.33       681.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grouping**\n",
        "\n",
        "\n",
        "*   Raggruppa i dati per `category`. Calcola il totale delle vendite (`sum` di `total_price` e la quantità media venduta)\n",
        "*   Raggruppa i dati `per month`. Quale mese ha generato il fatturato più alto?\n",
        "\n"
      ],
      "metadata": {
        "id": "d7uwPxvjUps_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Raggruppo i dati per category e calcolo il totale delle vendite e la quantità media venduta, faccio anche il conteggio del numero di vendite\n",
        "group_category = (\n",
        "    df_sales\n",
        "    .groupby('category', dropna=False)\n",
        "    .agg(\n",
        "        n_transactions=('product_id', 'size'),\n",
        "        total_revenue=('total_price', 'sum'),\n",
        "        avg_quantity=('quantity', 'mean')\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "print(group_category)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3Q-m00lfvqx",
        "outputId": "872ca7a8-c2c7-4afd-b352-4ee38127d628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      category  n_transactions  total_revenue  avg_quantity\n",
            "0  Electronics             255       89273.44      2.117647\n",
            "1      Fashion             535      210721.54      1.953271\n",
            "2         Home              83       14435.36      2.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Raggruppo i dati per month\n",
        "group_month = (\n",
        "    df_sales\n",
        "    .groupby('month', dropna=False)\n",
        "    .agg(\n",
        "        month_fatturato=('total_price', 'sum'),\n",
        "        n_vendite=('product_id', 'size'),\n",
        "        media_quantity=('quantity', 'mean')\n",
        "    )\n",
        "    .reset_index()\n",
        "    .sort_values('month_fatturato', ascending=False)\n",
        ")\n",
        "\n",
        "print(group_month)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45ExDJUBrPwB",
        "outputId": "a8168db7-4029-4516-8e5e-09e2d0464b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    month  month_fatturato  n_vendite  media_quantity\n",
            "9      10         33928.15         89        2.056180\n",
            "8       9         29283.95         78        1.935897\n",
            "5       6         29244.83         74        2.081081\n",
            "6       7         28865.34         82        2.012195\n",
            "11     12         28705.03         88        2.022727\n",
            "2       3         26630.36         78        1.948718\n",
            "3       4         26157.90         73        2.027397\n",
            "1       2         25329.14         73        1.917808\n",
            "0       1         24257.21         65        1.984615\n",
            "4       5         22571.27         58        2.034483\n",
            "7       8         20054.12         64        1.953125\n",
            "10     11         19403.04         51        2.117647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Il mese con fatturato più alto\n",
        "best_month = group_month.iloc[0]\n",
        "print(f\"Mese top: {int(best_month['month'])} con fatturato= {best_month['month_fatturato']:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24VxK1xIry9h",
        "outputId": "b1966bfb-bab5-4036-f889-972d65712ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mese top: 10 con fatturato= 33928.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pivot table**\n",
        "\n",
        "\n",
        "*   Crea una Pivot table che abbia come indice (`index`) la `category`, come colonne (`columns`) il `month`, e come valori (`values`) la somma delle quantità vendute. Fillate i valori mancanti con 0\n",
        "\n"
      ],
      "metadata": {
        "id": "1pDwr_u_nlhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pivot table: index=category, columns=month, values=sum(quantity)\n",
        "pivot_cat_month_qty = (\n",
        "    df_sales.pivot_table(\n",
        "        index='category',\n",
        "        columns='month',\n",
        "        values='quantity',\n",
        "        aggfunc='sum',\n",
        "        fill_value=0\n",
        "    )\n",
        ")\n",
        "\n",
        "print(pivot_cat_month_qty)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urMUl2eAohFT",
        "outputId": "7abb1ba0-4dfb-4847-f324-92ed2cee00a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "month          1     2      3     4     5     6      7     8     9      10  \\\n",
            "category                                                                     \n",
            "Electronics  28.0  46.0   42.0  45.0  38.0  50.0   40.0  36.0  62.0   58.0   \n",
            "Fashion      89.0  87.0  100.0  84.0  63.0  85.0  102.0  72.0  85.0  118.0   \n",
            "Home         12.0   7.0   10.0  19.0  17.0  19.0   23.0  17.0   4.0    7.0   \n",
            "\n",
            "month          11     12  \n",
            "category                  \n",
            "Electronics  43.0   52.0  \n",
            "Fashion      54.0  106.0  \n",
            "Home         11.0   20.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 5: Trasformazione e Normalizzazione Dati\n",
        "\n",
        "**Normalizzazione (Min-Max Scaling):**\n",
        "\n",
        "\n",
        "\n",
        "*   Utilizzando solo `numpy` (non funzioni pronte di sklearn), calcolare la normalizzazione Min-Max della colonna `total_price`.\n",
        "*   Formula: xnew​=max(x)−min(x)x−min(x)​\n",
        "\n",
        "\n",
        "*   Salva i risultati in una nuova colonna chiamata `total_price_norm`\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "krl-yufwpX1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Prendo la colonna come array numpy\n",
        "x = df_sales['total_price'].to_numpy(dtype=float)\n",
        "\n",
        "# Calcolo min e max (ignorando eventuali NaN)\n",
        "x_min = np.nanmin(x)\n",
        "x_max = np.nanmax(x)\n",
        "\n",
        "# Normalizzazione Min-Max: (x - min) / (max - min)\n",
        "den = x_max - x_min\n",
        "df_sales['total_price_norm'] = (x - x_min) / den if den != 0 else np.zeros_like(x)\n",
        "\n",
        "# controllo\n",
        "print(df_sales['total_price_norm'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixBixFxArJQX",
        "outputId": "19ef4014-4ed6-4558-ddd0-ebd57376f13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      0.481390\n",
            "1      0.460983\n",
            "2      0.265458\n",
            "3      0.632729\n",
            "4      0.273384\n",
            "         ...   \n",
            "868    0.092588\n",
            "869    0.101814\n",
            "870    0.085785\n",
            "871    0.203627\n",
            "872    0.101814\n",
            "Name: total_price_norm, Length: 873, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Binning (Suddivisione in classi):**\n",
        "\n",
        "\n",
        "*   Creare una nuova colonna `price_range` che categorizza il prezzo unitario dei prodotti\n",
        "*   'Low' se prezzo < 100\n",
        "\n",
        "\n",
        "*   'Medium' se 100 <= prezzo < 300\n",
        "*   'High' se prezzo >= 300\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jltFfbyJri-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_products['price_range'] = pd.cut(\n",
        "    df_products['price'],\n",
        "    bins=[-np.inf, 100, 300, np.inf],\n",
        "    labels=['Low', 'Medium', 'High'],\n",
        "    right=False  # intervalli: [a, b)\n",
        ")\n",
        "\n",
        "print(df_products['price_range'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8LXXydRtMK4",
        "outputId": "069fc861-b2a7-455c-827c-9e2ddf6c6583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    Medium\n",
            "1    Medium\n",
            "2    Medium\n",
            "3    Medium\n",
            "4    Medium\n",
            "5    Medium\n",
            "6      High\n",
            "7       Low\n",
            "8    Medium\n",
            "9    Medium\n",
            "Name: price_range, dtype: category\n",
            "Categories (3, object): ['Low' < 'Medium' < 'High']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 6: Preparazione per la Visualizzazione\n",
        "\n",
        "Immagina di dover creare un grafico a barre (es. con Matplotlib o Seaborn).\n",
        "\n",
        "**Aggregazione finale**\n",
        "\n",
        "\n",
        "\n",
        "*   rea un DataFrame chiamato `df_chart` che contenga il numero di clienti unici (`customer_id)` per ogni brand.\n",
        "*   Ordina questo DataFrame in modo decrescente\n",
        "\n",
        "\n",
        "*   \n",
        "*   Voce elenco\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5E9oq4NSxFcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parte 6: Preparazione per la Visualizzazione**\n",
        "\n",
        "Immagina di dover creare un grafico a barre (es. con Matplotlib o Seaborn).\n",
        "\n",
        "11. **Aggregazione Finale**:\n",
        "    - Crea un DataFrame chiamato `df_chart` che contenga il numero di clienti unici (`customer_id`) per ogni `brand`.\n",
        "    - Ordina questo DataFrame in modo decrescente.\n",
        "    - Esporta l'output su un file CSV chiamato `report_vendite_brand.csv` senza indice.\n",
        "          "
      ],
      "metadata": {
        "id": "8R-CM1o2Q5p5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uyyZEC1hxmYf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}